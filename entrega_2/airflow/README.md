# DAG

Se definiÃ³ un flujo utilizando **Apache Airflow**, **MLflow**, y un **Decision Tree Classifier**. El pipeline permite:

- Validar de archivos de entrada
- Verificar de *data drift*
- Entrenar condicionalmente el modelo
- Registrar mÃ©tricas y versiones del modelo

---

## VÃ­deo EjecuciÃ³n

https://drive.google.com/file/d/1wOFsBffIQlKMO0K7RB22nPQaDZ545M0M/view?usp=sharing

## ğŸ”§ Estructura General del DAG

El `DAG` principal contiene las siguientes tareas:

| Tarea                   | DescripciÃ³n |
|------------------------|-------------|
| `check_data`           | Verifica que existan los archivos `transacciones.parquet`, `clientes.parquet` y `productos.parquet`. |
| `branch_drift_check`   | LÃ³gica condicional para decidir si se reentrena el modelo, usando `detect_drift()`. |
| `train_model`          | Ejecuta el script `train_decision_tree.py` si hay *drift*. |
| `drift_detection`      | Registra en logs que se realizÃ³ una verificaciÃ³n de *drift*. |
| `skip_training`        | Rama alternativa si no hay *drift*. |
| `end`                  | FinalizaciÃ³n. |

---

## Diagrama de Flujo del Pipeline

<p align="center">
  <img src="./imgs/Pipeline.png" alt="VisualizaciÃ³n del DAG en Airflow" width="300"/>
</p>

---

## ğŸ–¥ï¸ VisualizaciÃ³n en Airflow UI

Una vez desplegado en el entorno de Airflow, el DAG se ve asÃ­:

<p align="center">
  <img src="./imgs/Capture.png" alt="VisualizaciÃ³n del DAG en Airflow" width="800"/>
</p>

---

## Entrenamiento del Modelo

El entrenamiento se realiza con el script `train_decision_tree.py` (carpeta *scripts*), el cual:

1. Carga y prepara las combinaciones cliente-producto-semana.
2. Crea el objetivo binario (`target=1` si hubo compra, `0` si no).
3. Aplica transformaciÃ³n de fechas, imputaciÃ³n, escalado y one-hot encoding.
4. Entrena un `DecisionTreeClassifier`.
5. Usa `MLflow` para registrar:
   - MÃ©tricas
   - ParÃ¡metros del modelo
   - `joblib`

---

## DetecciÃ³n de Drift

La funciÃ³n `detect_drift()` compara la media de la variable `items` entre los nuevos datos (`transacciones.parquet`) y las estadÃ­sticas previas (`train_feature_stats.joblib`). Se estima conveniente utilizar mÃ¡s estadÃ­sticos para realizar la comparaciÃ³n, pero por el momento se utiliza un *scheduler* diario para evitar drift.

- Si no existen estadÃ­sticas previas para comparar se fuerza reentrenamiento.
- Si el delta entre medias es mayor a `0.1` âœ se considera *drift significativo*.

Esto permite mantener el modelo actualizado frente a cambios en el comportamiento de compra.

---

## LÃ³gica de IntegraciÃ³n Continua

El diseÃ±o del DAG permite que el modelo se actualice automÃ¡ticamente si:

- Se agregan nuevos datos (el DAG corre diario).
- Se detecta *drift* estadÃ­stico relevante.
- El pipeline es **modular y extensible**, por lo que puedes reemplazar el modelo o lÃ³gica de drift fÃ¡cilmente.

---

## Estructura (fundamental) del Proyecto

```
.
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ decision_tree_dag.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_decision_tree.py
â”‚   â””â”€â”€ detect_drift.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ decision_tree_model.joblib
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ transacciones.parquet
â”‚   â”œâ”€â”€ clientes.parquet
â”‚   â””â”€â”€ productos.parquet
```